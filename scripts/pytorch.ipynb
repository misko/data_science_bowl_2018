{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import math\n",
    "from functools import reduce\n",
    "from scipy import stats\n",
    "\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline\n",
    "from skimage.color import rgb2grey, rgb2hsv, hsv2rgb, grey2rgb, rgba2rgb\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage import img_as_float, img_as_ubyte, img_as_uint\n",
    "from skimage.morphology import reconstruction\n",
    "from skimage.util import invert\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.color import label2rgb\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "from skimage.morphology import erosion, dilation, binary_dilation, opening, closing, white_tophat\n",
    "from skimage.morphology import disk\n",
    "\n",
    "import sklearn\n",
    "from skimage.morphology import label\n",
    "\n",
    "import utils\n",
    "from utils import show_images, plot_img_and_hist, add_contour\n",
    "from loss import show_compare_gt\n",
    "\n",
    "#import ipy_autoreload\n",
    "#%autoreload 2 \n",
    "#%aimport your_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform = reload(transform)\n",
    "utils = reload(utils)\n",
    "loss=reload(loss)\n",
    "architectures = reload(architectures)\n",
    "main = reload(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from utils import exceptions_str\n",
    "from skimage.morphology import reconstruction\n",
    "from skimage import img_as_float, exposure\n",
    "from skimage.util import invert\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import erosion, dilation, binary_dilation, binary_opening, opening, closing, white_tophat\n",
    "from skimage.morphology import disk\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "\n",
    "def parametric_pipeline(img,\n",
    "                invert_thresh_pd = .5,\n",
    "                circle_size = 7,\n",
    "                disk_size=10,\n",
    "                min_distance=9,\n",
    "                use_watershed=False\n",
    "                ):\n",
    "    try:\n",
    "        circle_size = np.clip(int(circle_size), 1, 30)\n",
    "        if use_watershed:\n",
    "            disk_size = np.clip(int(disk_size), 0, 50)\n",
    "            min_distance = np.clip(int(min_distance), 1, 50)\n",
    "\n",
    "        # Invert the image in case the objects of interest are in the dark side                                                                                  \n",
    "\n",
    "        thresh = threshold_otsu(img)\n",
    "        img_th = img > thresh\n",
    "\n",
    "        if len(np.where(img_th)[0]) > invert_thresh_pd * img.size:\n",
    "            img=invert(img)\n",
    "\n",
    "        # morphological opening (size tuned on training data)                                                                                                    \n",
    "        #circle7=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(circle_size, circle_size))                                                                         \n",
    "        circle7=disk(circle_size / 2.0)\n",
    "        img_open = opening(img, circle7)\n",
    "        #img_open = cv2.morphologyEx(img, cv2.MORPH_OPEN, circle7)                                                                                               \n",
    "        #return img_open                                                                                                                                         \n",
    "\n",
    "        thresh = threshold_otsu(img_open)\n",
    "        img_th = (img_open > thresh).astype(int)\n",
    "     # second morphological opening (on binary image this time)                                                                                               \n",
    "        bin_open = binary_opening(img_th, circle7)\n",
    "        if not use_watershed:\n",
    "            return ndi.label(bin_open)[0], thresh\n",
    "\n",
    "        # WATERSHED                                                                                                                                              \n",
    "        selem=disk(disk_size)\n",
    "        dil = binary_dilation(bin_open, selem)\n",
    "        img_dist = ndi.distance_transform_edt(dil)\n",
    "        local_maxi = peak_local_max(img_dist,\n",
    "                                    min_distance=min_distance,\n",
    "                                    indices=False,\n",
    "                                    exclude_border=False)\n",
    "        markers = ndi.label(local_maxi)[0]\n",
    "        cc = watershed(-img_dist, markers, mask=bin_open, compactness=0, watershed_line=True)\n",
    "\n",
    "        return cc\n",
    "    except:\n",
    "        logging.error(\"Error in parametric pipeline:\\n%s\" % exceptions_str())\n",
    "        return np.zeros_like(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_transform(img, mask, mask_seg):\n",
    "    # HACK (make dims consistent, first one is channels)                                                                                                         \n",
    "    if len(mask.shape) == 2:\n",
    "        mask = np.expand_dims(mask, 2)\n",
    "    if len(mask_seg.shape) == 2:\n",
    "        mask_seg = np.expand_dims(mask_seg, 2)\n",
    "    #img, mask, mask_seg = random_rotate90_transform2(img, mask, mask_seg)\n",
    "    img = ToTensor()(img)\n",
    "    mask = torch.from_numpy(np.transpose(mask, (2, 0, 1))).float()\n",
    "    mask_seg = torch.from_numpy(np.transpose(mask_seg, (2, 0, 1))).float()\n",
    "    return img, mask, mask_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils=reload(utils)\n",
    "import utils\n",
    "import main\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "dsb_data_dir = os.path.join('..', '..', 'input')\n",
    "stage_name = 'stage1'\n",
    "\n",
    "\n",
    "dset = NucleusDataset(dsb_data_dir, stage_name, transform=train_transform)\n",
    "\n",
    "# hack: this image format (1388, 1040) occurs only ones, stratify complains .. \n",
    "dset.data_df = dset.data_df[dset.data_df['size'] != (1388, 1040)]\n",
    "\n",
    "stratify = dset.data_df['images'].map(lambda x: '{}'.format(x.size))\n",
    "train_dset, valid_dset = dset.train_test_split(test_size=0.05, random_state=1, shuffle=True, stratify=stratify)\n",
    "train_loader = DataLoader(train_dset, batch_size=1,shuffle=True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size=1,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import architectures\n",
    "model = architectures.CNN()\n",
    "path='/Users/stefan/Documents/nucleus/data_science_bowl_2018/scripts/experiments/bce_img_weight_6l/model_save_bce_img_weight_6l_best.pth.tar'\n",
    "#path='/Users/stefan/Documents/nucleus/data_science_bowl_2018/scripts/experiments/mse_sgd/model_save_mse_sgd_best.pth.tar'\n",
    "#path='/Users/stefan/Documents/nucleus/data_science_bowl_2018/scripts/experiments/dice/model_save_dice_best.pth.tar'\n",
    "main.load_checkpoint(path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISABLE AUGMENTATION!\n",
    "train_dset.transform=train_transform\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "model.eval()\n",
    "preds = []\n",
    "for i in tqdm(range(len(train_dset.data_df))):\n",
    "    img, (mask, mask_seg) = train_dset[i]\n",
    "    pred = model(Variable(img.unsqueeze(0),requires_grad=False)).data.numpy().squeeze()\n",
    "    preds.append(pred)\n",
    "train_dset.data_df['pred'] = preds\n",
    "\n",
    "train_dset.data_df['pred'].iloc[0]\n",
    "#plt.imshow(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate IOU For All Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshs = []\n",
    "pred_labels = []\n",
    "ious = []\n",
    "for i in tqdm(range(len(train_dset.data_df))):\n",
    "    img_th, th = parametric_pipeline(train_dset.data_df['pred'].iloc[i],circle_size=4)\n",
    "    ious.append(iou_metric(img_th, train_dset.data_df['masks'].iloc[i]))\n",
    "    threshs.append(th)\n",
    "    pred_labels.append(img_th)\n",
    "train_dset.data_df['thresh'] = threshs\n",
    "train_dset.data_df['iou'] = ious\n",
    "train_dset.data_df['pred_label'] = pred_labels\n",
    "\n",
    "\n",
    "#print np.mean(ious),np.median(ious)\n",
    "#diagnose_errors(img_th[0][0],img_th[0][1])\n",
    "#show_compare_gt(pred[2][0],pred[2][1],circle_size=10)\n",
    "#print pred[0][0].dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.describe(train_dset.data_df['thresh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_dset.data_df['thresh'].map(lambda x: min(x, .4)), 50, normed=1, facecolor='green', alpha=0.75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.describe(train_dset.data_df['iou'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_dset.data_df['iou'], 100, normed=1, facecolor='green', alpha=0.75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_dset.data_df['thresh'].map(lambda x: min(x, .36)),train_dset.data_df['iou'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Fixed Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=train_dset.data_df['pred'].iloc[0]\n",
    "def ious_at_thresh(thresh):\n",
    "    l = []\n",
    "    for i in tqdm(range(len(train_dset.data_df))):\n",
    "        img_th = (train_dset.data_df['pred'].iloc[i] > thresh).astype(int)\n",
    "        l.append(iou_metric(img_th, train_dset.data_df['masks'].iloc[i]))\n",
    "    return l\n",
    "\n",
    "threshs=np.linspace(.26, .34, 20)\n",
    "i = [np.mean(ious_at_thresh(x)) for x in threshs]\n",
    "plt.plot(threshs,i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot All Images With IOU 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset.data_df['masks'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = np.where(np.abs(train_dset.data_df['iou'] - 0.1) <=0.1)\n",
    "print sel\n",
    "for i in np.nditer(sel):\n",
    "    i = np.asscalar(i)\n",
    "    show_images([train_dset.data_df['images'].iloc[i],\n",
    "        train_dset.data_df['pred'].iloc[i],\n",
    "        train_dset.data_df['pred_label'].iloc[i],\n",
    "        train_dset.data_df['masks'].iloc[i]], 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=12\n",
    "show_compare_gt(train_dset.data_df['images'].iloc[i], \n",
    "                train_dset.data_df['pred_label'].iloc[i], \n",
    "                train_dset.data_df['masks'].iloc[i])\n",
    "#utils.show_with_contour(train_dset.data_df['images'].iloc[i], \n",
    "#                        train_dset.data_df['masks'].iloc[i],\n",
    "#                       color='green')\n",
    "#show_images([train_dset.data_df['images'].iloc[i], \n",
    "#                        train_dset.data_df['masks'].iloc[i]])\n",
    "\n",
    "#ov = label2rgb(train_dset.data_df['pred_label'].iloc[i], train_dset.data_df['images'].iloc[i])\n",
    "#fig, ax = plt.subplots(figsize=(20, 12))\n",
    "#ax.imshow([1, 1, 1] * ov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary of image formats\n",
    "dset.data_df.groupby(['format','mode','size']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modes = dset.data_df['images'].map(lambda x: x.mode)\n",
    "sizes = dset.data_df['images'].map(lambda x: x.size)\n",
    "print np.unique(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "print_every = 10\n",
    "save_every = 10\n",
    "eval_every = 10\n",
    "    \n",
    "epochs = 10\n",
    "\n",
    "if 1:\n",
    "    model = CNN()\n",
    "    it = 0\n",
    "    best_loss = 1e20\n",
    "    best_it = 0\n",
    "    stats = []\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = loss.DiceLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9, weight_decay=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # adjust_learning_rate(optimizer, epoch)\n",
    "    it, best_loss, best_it = train(train_loader, valid_loader, model, criterion, optimizer, stats, epoch, eval_every, print_every, save_every)\n",
    "print it, best_loss, best_it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as TT\n",
    "#monkeypatch(dset, 'transform', train_transform)\n",
    "#train_dset.transform=train_transform\n",
    "#valid_dset.transform=train_transform\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for img,(_,mask) in iter(train_loader):\n",
    "    break\n",
    "\n",
    "\n",
    "pred = model(Variable(img,requires_grad=False))\n",
    "color_adjust = model.get_color_adjust(Variable(img,requires_grad=False))\n",
    "coarse = model.get_coarse(Variable(img,requires_grad=False))\n",
    "\n",
    "show_images([img[0],color_adjust.data[0],mask[0]])\n",
    "#show_images([img[0],coarse[0].data[0],coarse[1].data[0],coarse[2].data[0],mask[0]])\n",
    "#show_images([img[0],pred.data[0],mask[0]])\n",
    "\n",
    "#pred = ToPILImage()(pred.data[0])\n",
    "#ii = np.array(pred.data[0].squeeze())\n",
    "#plt.imshow(ii,cmap='gray')\n",
    "#ii[abs(ii-0.1425)<=0.01]=1\n",
    "#ii=mask[0]\n",
    "#print ii.min(), ii.max(), ii.mean(), stats.mode(ii.flatten())\n",
    "#show_images([img[0],pred.data[0],mask[0]])\n",
    "#print criterion(pred,Variable(mask))\n",
    "#print ((pred.data[0]-mask[0])* (pred.data[0]-mask[0])).sum()/pred.data[0].numel()\n",
    "#print ((mask[0]-mask[0].mean())* (mask[0]-mask[0].mean())).sum()/mask[0].numel()\n",
    "#print pred.data[0].size()\n",
    "#plot_img_and_hist(pred.data[0])\n",
    "#plot_img_and_hist([img,mask])\n",
    "#mask.mean()\n",
    "#mask.shape\n",
    "#show_img([img,mask])\n",
    "#train_dset.transform\n",
    "#train_dset.transform=transforms.ToTensor()\n",
    "#train_dset.transform\n",
    "#TT.ToPILImage()(img)\n",
    "#show_images(pred.data[0])\n",
    "#plt.imshow(ToPILImage()(pred.data[0]))\n",
    "#plt.imshow(pred.data[0].numpy().squeeze())\n",
    "#plt.imshow(img_as_float(pred.data[0].numpy().squeeze()))\n",
    "\n",
    "#print isinstance(pred.data[0], torch.Tensor)\n",
    "\n",
    "\n",
    "#print baseline(train_loader, valid_loader, criterion, 1000)\n",
    "#def is_inverted(img,invert_thresh_pd=10.0):\n",
    "#    img_grey = img_as_ubyte(rgb2grey(img))\n",
    "#    img_th = cv2.threshold(img_grey,0,255,cv2.THRESH_OTSU)[1]\n",
    "#    return np.sum(img_th==255)>((invert_thresh_pd/10.0)*np.sum(img_th==0))\n",
    "\n",
    "#print is_inverted(train_dset.data_df['images'].iloc[0])\n",
    "#x = train_dset.data_df['images'].map(is_inverted)\n",
    "#print np.where(train_dset.data_df['inv'])\n",
    "#ii = train_dset.data_df['images'].iloc[71]\n",
    "#plt.imshow(rgb2grey(ii),cmap='binary')\n",
    "#plt.imshow(ii[:10,:10]-5)\n",
    "#ii[:10,:10]\n",
    "\n",
    "#show_images(rgb2grey(ii))\n",
    "\n",
    "#plot_img_and_hist(rgb2grey(ii))\n",
    "#train_dset.data_df['id'].iloc[71]\n",
    "#print ii.dtype, ii.mean(), ii.max(), ii.min(), stats.mode(ii.flatten())\n",
    "#plt.imshow(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel correlation plot\n",
    "x=pred.data[0].numpy().flatten()\n",
    "y=mask[0].numpy().flatten()\n",
    "plt.scatter(y,x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch,stats=load_model(model, optimizer)\n",
    "print epoch, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss=reload(loss)\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "#post_process=reload(post_process)\n",
    "import loss\n",
    "import post_process\n",
    "from post_process import parametric_pipeline\n",
    "from loss import iou_metric, diagnose_errors, show_compare_gt\n",
    "#model.eval()\n",
    "#pred = [(model(Variable(img,requires_grad=False)).data.numpy().squeeze(), mask.numpy().squeeze()) for img, (mask,mask_seg) in tqdm(iter(train_loader))]\n",
    "#pred = [(ToPILImage()(img.squeeze()),mask.numpy().squeeze()) for img, (mask,mask_seg) in iter(valid_loader)]\n",
    "#img_th = [(parametric_pipeline(rgb2grey(np.asarray(img)),circle_size=4), mask) for img, mask in pred]\n",
    "#ious = [iou_metric(i,m) for (i,m) in img_th]\n",
    "print np.mean(ious),np.median(ious)\n",
    "#diagnose_errors(img_th[0][0],img_th[0][1])\n",
    "#show_compare_gt(pred[2][0],pred[2][1],circle_size=10)\n",
    "#print pred[0][0].dtype\n",
    "#pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dice 0.239599661927 0.221256282842\n",
    "jaccard 0.23728979728 0.189091591261\n",
    "bce 0.279290088953 0.217723006553\n",
    "mse 0.304971608193 0.309523258999\n",
    "new arch\n",
    "mse 0.158894834172 0.114834653566\n",
    "bce mean = 0.17207, med = 0.12120\n",
    "dice mean = 0.24912, med = 0.19799\n",
    "img-weighted bce 0.22999, med = 0.18525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### dset.data_df['masks_unlabeled']=dset.data_df['masks_unlabled']\n",
    "\n",
    "#for i,(img,mask) in enumerate(valid_loader):\n",
    "#    break\n",
    "\n",
    "#print mask[1].dtype\n",
    "#dset.data_df['masks'].iloc[0].max()\n",
    "#ii=np.array(((1,2,3),(4,5,5)),dtype=np.uint8)\n",
    "#print torch.from_numpy(ii)\n",
    "img=dset.data_df['images'].iloc[0]\n",
    "m1=dset.data_df['masks'].iloc[0]\n",
    "m2=dset.data_df['masks_seg'].iloc[0]\n",
    "ii,mm1,mm2=train_transform(img,m1,m2)\n",
    "print mm1.shape,mm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=np.zeros((2,3,1))\n",
    "print np.flip(ii,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.rot90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "\n",
    "xs = map(itemgetter(0), stats)\n",
    "ys = map(itemgetter(1), stats)\n",
    "zs = map(itemgetter(2), stats)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots( nrows=1, ncols=1 )\n",
    "ax.plot(xs,ys,'g')\n",
    "ax.plot(xs,zs,'r')\n",
    "plt.show()\n",
    "#fig.savefig('path/to/save/image/to.png')   # save the figure to file\n",
    "#plt.close(fig)    # close the figure\n",
    "#print xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame({'x':[1,2,3,4],'y':[1,2,3,4]})\n",
    "x['x'].map(lambda x: x + 1)\n",
    "#x['x'].map(lambda x: x + 1)\n",
    "[x+1 for x in tqdm(x['x'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_object\n",
    "img=load_object('/Users/stefan/Documents/nucleus/data_science_bowl_2018/scripts/FOOTPRINT.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images([img.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
